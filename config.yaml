# Semantic Chaos Bench Configuration

# Perturbation levels to test
epsilon_levels:
  - 0.01  # minimal perturbation
  - 0.05  # small perturbation
  - 0.10  # moderate perturbation
  - 0.20  # large perturbation

# Models to benchmark
models:
  openai:
    - gpt-4
    - gpt-4-turbo
    - gpt-3.5-turbo
  anthropic:
    - claude-3-5-sonnet-20241022
    - claude-3-opus-20240229
    - claude-3-sonnet-20240229
  google:
    - gemini-pro
  replicate:
    - meta/llama-3-70b
    - meta/llama-3-8b
    - mistralai/mistral-7b-instruct-v0.2
    - mistralai/mixtral-8x7b-instruct-v0.1
  together:
    - meta-llama/Llama-3-70b-chat-hf
    - mistralai/Mixtral-8x7B-Instruct-v0.1

# Prompt categories
prompt_categories:
  - factual
  - creative
  - reasoning
  - code
  - conversational

# Generation parameters
generation:
  temperatures: [0.0, 0.7, 1.0]
  max_tokens: 500
  multi_step_count: 5

# Experiment settings
experiment:
  pairs_per_category: 100
  random_seed: 42
  cache_responses: true

# Embedding settings
embeddings:
  model: "all-MiniLM-L6-v2"  # Fast, good quality
  # Alternative: "all-mpnet-base-v2"  # Higher quality, slower
  device: "mps"  # Metal Performance Shaders for Mac
  batch_size: 32

# API settings
api:
  max_retries: 3
  retry_delay: 1.0  # seconds
  timeout: 30  # seconds
  rate_limit_delay: 0.5  # seconds between requests

# Output settings
output:
  results_dir: "experiments/results"
  cache_dir: "data/cache"
  plot_format: "png"
  plot_dpi: 300

