# Semantic Chaos Bench Configuration

# Perturbation levels to test
epsilon_levels:
  - 0.01  # minimal perturbation
  - 0.05  # small perturbation
  - 0.10  # moderate perturbation
  - 0.20  # large perturbation

# Models to benchmark
models:
  openai:
    - gpt-5
    - gpt-5-mini
    - gpt-5-nano
  anthropic:
    - claude-4-5-sonnet-20241022
    - claude-haiku-4-5
  google:
    - gemini-pro-latest  # Alias for latest pro
    - gemini-flash-latest  # Alias for latest flash
  replicate:
    - meta/llama-3-8b
    - mistralai/mistral-7b-instruct-v0.2
  together:
    - mistralai/Mixtral-8x7B-Instruct-v0.1

# Prompt categories
categories:
  - factual
  - creative
  - reasoning
  - code

# Generation parameters
generation:
  temperatures: [0.0, 0.7, 1.0]
  max_tokens: 500
  multi_step_count: 5

# Experiment settings
experiment:
  pairs_per_category: 100
  random_seed: 42
  cache_responses: true

# Embedding settings
embedding_model: "all-MiniLM-L6-v2"  # Fast, good quality
# Alternative: "all-mpnet-base-v2"  # Higher quality, slower

# Paraphrase generation settings
paraphrase_model: "gemini-2.0-flash-exp"  # Model to use for generating paraphrases
n_paraphrases: 100  # Number of paraphrases to generate per base prompt
n_pairs_per_prompt: 10  # Number of pairs to generate per base prompt
tolerance: 0.01  # Tolerance for epsilon matching (epsilon Â± tolerance)

# API settings
api:
  max_retries: 3
  retry_delay: 1.0  # seconds
  timeout: 30  # seconds
  rate_limit_delay: 0.5  # seconds between requests

# Output settings
output:
  results_dir: "experiments/results"
  cache_dir: "data/cache"
  plot_format: "png"
  plot_dpi: 300

